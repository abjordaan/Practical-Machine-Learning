library(ISLR)
data("Wage")
summary(Wage)
inTrain <= createDataPartition(y=Wage$wage, p=0.7,list=FALSE)
head(inTrain)
rm(training)
rm(testing)
traingin <- Wage[inTrin,]
training <- Wage[inTrain,]
testing <- Wage[-inTrain]
dim(training)
dim(testing)
str(Wage)
head(inTrain)
rm(inTrain)
rm(list=ls())
ls()
inTrain <= createDataPartition(y=Wage$wage, p=0.7,list=FALSE)
head(inTrain)
inTrain <- createDataPartition(y=Wage$wage, p=0.7,list=FALSE)
head(inTrain)
training <- Wage[inTrain,]
testing <- Wage[-inTrain]
dim(training)
dim(testing)
featurePlot(x=training)
featurePlot(x=training[,c("age","education","jobclass")], y=training$age,plot="pairs")
qplot(age,wage,data=training)
qplot(age,wage,color=jobclassdata=training)
qplot(age,wage,color=jobclass,data=training)
qq <- qplot(age,wage,color=education,data=training)
qq + geom_smooth(method="lm", formula=x~y)
qq + geom_smooth(method="lm", formula=y~x)
library("Hmisc", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
cutWage <- cut2(training$wage, g=3)
table(cutWage)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
rm(list=rm())
ls()
rm(list=ls())
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
head(concrete)
plot(CompressiveStrength,Age,data=training)
names <- colnames(concrete)
names
names[-length(names)]
length(names)
-length(names)
names <- names[-length(names)]
names
featurePlot(x = training[, names], y = training$CompressiveStrength, plot = "pairs")
seq_along(1:nrow(training))
table(training)
str(training)
index <- seq_along(1:nrow(training))
nrow(training)
training
ggplot(data = training, aes(x = index, y = CompressiveStrength)) + geom_point() + theme_bw(
)
cutCS <- cut2(training$CompressiveStrength, g = 4)
summary(cutCS)
ggplot(data = training, aes(y = index, x = cutCS)) + geom_boxplot() + geom_jitter(col = "blue") + theme_bw(
)
featurePlot(x = training[, names], y = cutCS, plot = "box")
rm(list=s())
rm(list=ls())
ls()
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
head(training)
hist(Superplasticizer)
hist(training$Superplasticizer)
rm(list=ls())
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
rm(list=ls())
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
inTrain <- createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
inTrain <- createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
inTrain <- createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
which(sapply(adData,class)=="factor")
ncol(training)
head(testing)
str(testing)
summary(training$diagnosis)
str(adData)
which(sapply(adData,class)=="factor")
head(adData, 2)
training$diagnosis = as.numeric(training$diagnosis)
str(training)
p <- prcomp(training[,grep('^IL',names(training))])
p$rotation[,1:7]
qplot(1:length(p$sdev),p$sdev / sum(p$sdev))
which(cumsum(p$sdev) / sum(p$sdev) <= .9)
preProc <- preProcess(training[,grep('^IL',names(training))],method="pca",thres=.9)
preProc
rm(list=ls())
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
inTrain <- createDataPartition(y=segmentationOriginal$Case, p=0.7, list =FALSE)
set.seed(125)
training <- segmentationOriginal[inTrain];
test <- segmentationOriginal[-inTrain];
dim(training)
dim(test)
head(segmentationOriginal)
inTrain <- createDataPartition(y=segmentationOriginal$Case, p=0.7, list =FALSE)
head(inTrain)
training <- segmentationOriginal[inTrain,];
test <- segmentationOriginal[-inTrain,];
dim(test)
dim(training)
modFit <- train(Case ~. , method="rpart", data=training)
install.packages("pgmm")
install.packages("ElemStatLearn")
install.packages("pgmm")
modFit <- train(Case ~. , method="rpart", data=training)
install.packages("e1071")
modFit <- train(Case ~. , method="rpart", data=training)
print(modFit$finalModel)
head(training)
str(training)
modFit <- train(Class ~. , method="rpart", data=training)
print(modFit$finalModel)
suppressMessages(library(rattle))
install.packages("rattle")
install.packages("rpart.plot")
fancyRpartPlot(modFit$finalModel)
install.packages("fancyRpartPlot")
library("rpart.plot", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
fancyRpartPlot(modFit$finalModel)
suppressMessages(library(rattle))
library("rattle", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
fancyRpartPlot(modFit$finalModel)
data(olive)
olive = olive[,-1]
library(pgmm)
data(olive)
olive = olive[,-1]
str(olive)
table(olive$Area)
olive
modOlive <- train(Area ~. , method="rpart", data=olive)
colMeans(olive)
t(colMeans(olive))
newdata = as.data.frame(t(colMeans(olive)))
predict(modOlive,newdata=newdata)
rm(list=ls())
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
modelSA <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data = trainSA, method = "glm", family = "binomial")
missClass(testSA$chd, predict(modelSA, newdata = testSA))
missClass = function(values, prediction){sum(((prediction > 0.5) * 1) != values) / length(values)}
missClass(testSA$chd, predict(modelSA, newdata = testSA))
missClass(trainSA$chd, predict(modelSA, newdata = trainSA))
quit()
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
library(caret)
function(varImp)
)
?varImp
install.packages("randomForest")
modFit <- randomForest(vowel.train$y ~. , data = vowel.train)
library(ElemStatLearn)
library(randomForest)
modFit <- randomForest(vowel.train$y ~. , data = vowel.train)
varImp(modFit)
varImp(modFit, decreasing = T)
order(varImp(modFit), decreasing = T)
varImp(modFit)
head(vowel.train)
str(vowel.train)
vowel.train$y <- as.factor(vowel.train$y)
str(vowel.train)
library(randomForest)
modvowel <- randomForest(y ~ ., data = vowel.train)
order(varImp(modvowel), decreasing = T)
set.seed(33833)
order(varImp(modvowel), decreasing = T)
rm(list=ls())
ls()
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
library(randomForest)
modvowel <- randomForest(y ~ ., data = vowel.train)
order(varImp(modvowel), decreasing = T)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
str(vowel.train)
vowel.test$y <- as.factor(vowel.test$y)
str(vowel.train)
vowel.test$y <- as.factor(vowel.test$y)
str(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
str(vowel.train)
set.seed(33833)
library("caret", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
modrf <- train(y ~ . , data=vowel.train, method="rf")
modgbm <- train(y ~ . , data=vowel.train, method="gbm")
install.packages("gbm")
modrf
modgbm
pred_rf <- predict(mod_rf, vowel.test)
predrf <- predict(modrf, vowel.test)
predgbm <- predict(modgbm, vowel.test)
confusionMatrix(predrf, vowel.test$y)$overall[1]
confusionMatrix(predgdm, vowel.test$y)$overall[1]
confusionMatrix(predgbm, vowel.test$y)$overall[1]
rm(list=ls())
ls()
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
str(training)
set.seed(62433)
mod_rf <- train(diagnosis ~ ., data = training, method = "rf")
mod_gbm <- train(diagnosis ~ ., data = training, method = "gbm")
mod_lda <- train(diagnosis ~ ., data = training, method = "lda")
pred_rf <- predict(mod_rf, testing)
pred_gbm <- predict(mod_gbm, testing)
pred_lda <- predict(mod_lda, testing
)
predDF <- data.frame(pred_rf, pred_gbm, pred_lda, diagnosis = testing$diagnosis)
combModFit <- train(diagnosis ~ ., method = "rf", data = predDF)
combPred <- predict(combModFit, predDF)
confusionMatrix(pred_rf, testing$diagnosis)$overall[1]
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
rm(list=ls())
ls9()
ls()
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
ls()
set.seed(233)
mod_lasso <- train(CompressiveStrength ~ ., data = training, method = "lasso")
library(elasticnet)
plot.enet(mod_lasso$finalModel, xvar = "penalty", use.color = TRUE)
rm(list=ls())
library(lubridate)
dir()
dat = read.csv("gaData.csv")
dat
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,
]
tstrain = ts(training$visitsTumblr)
head(tstrain)
tstrain
mod_ts <- bats(tstrain)
library(forecast)
install.packages("forecast")
library(forecast)
mod_ts <- bats(tstrain)
fcast <- forecast(mod_ts, level = 95, h = dim(testing)[1])
sum(fcast$lower < testing$visitsTumblr & testing$visitsTumblr < fcast$upper) / dim(testing)[1]
rm(list=ls())
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testin
testing
testing = concrete[ -inTrain,]
set.seed(325)
library(e1071)
mod_svm <- svm(CompressiveStrength ~ ., data = training)
pred_svm <- predict(mod_svm, testing)
head(pred_svm)
head(mod_svm)
accuracy(pred_svm, testing$CompressiveStrength)
quit
quit()
library(caret)
library(rpart)
library(rpart.plot)
library(randomForest)
library(corrplot)
if(!file.exists("./data")){dir.create("./data")}
getwd()
setwd("~/Documents/Training/Coursera/RWorkingDirectory/C8")
if(!file.exists("./data")){dir.create("./data")}
if(!file.exists("./data")){dir.create("./data")}
if(!file.exists("./data")){dir.create("./data")}
if(!file.exists("/data/pml-training.csv")) {
trainUrl <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(trainUrl,pml-training.csv)
''
)
trainUrl <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
trainUrl
download.file(trainUrl,pml-training.csv)
download.file(trainUrl,pmltraining.csv)
download.file(trainUrl,pmltraining.csv, method="curl")
download.file(trainUrl,pmltraining, method="curl")
download.file(trainUrl , test)
url  <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(url, destfile, method = "auto", quiet=FALSE)
trainUrl <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
DTest <- fread(trainUrl)
?fread
library("data.table", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
DTest <- fread(trainUrl)
url  <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(url, destfile="./data/pml-training.csv", method="curl", quiet=FALSE)
if(!file.exists("/data/pml-testing.csv")) {
url  <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(url, destfile="./data/pml-testing.csv", method="curl", quiet=FALSE)
}
if(!file.exists("/data/pml-testing.csv")) {
url  <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(url, destfile="./data/pml-testing.csv", method="curl", quiet=FALSE)
}
if(!file.exists("/data/pml-testing.csv")) {
url  <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(url, destfile="./data/pml-testing.csv", method="curl", quiet=FALSE)
}
if(!file.exists("./data/pml-testing.csv")) {
url  <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(url, destfile="./data/pml-testing.csv", method="curl", quiet=FALSE)
}
if(!file.exists("./data/pml-training.csv")) {
url  <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(url, destfile="./data/pml-training.csv", method="curl", quiet=FALSE)
}
trainDF <- read.csv("./data/pml-training.csv")
testDF <- read.csv("./data/pml-test.csv")
testDF <- read.csv("./data/pml-testing.csv")
dim(trainDF)
dim(testDF)
sum(complete.cases(trainDF))
sum(complete.cases(testDF))
summary(trainDF)
sum(complete.cases(trainRaw))
trainDF <- trainDF[, colSums(is.na(trainDF)) == 0]
sum(complete.cases(trainDF))
sum(complete.cases(testDF))
sum(complete.cases(trainDF))
sum(complete.cases(testDF))
na.omit(trainDF)
trainDF <- na.omit(trainDF)
sum(complete.cases(trainDF))
testDF
trainDF <- complete.cases(trainDF)
x <- trainDF[complete.cases(trainDF), ]
trainDF <- read.csv("./data/pml-training.csv")
testDF <- read.csv("./data/pml-testing.csv")
x <- trainDF[complete.cases(trainDF), ]
x
sum(x)
str(x)
trainDF$classe
set.seed(10)
inTrain <- createDataPartition(y=trainDF$classe, p=0.7, list=F)
training <- trainDF[inTrain, ]
testing <- trainDF[-inTrain, ]
nzv <- nearZeroVar(training)
nzv
str(trainDF)
grepl("^X|user|timestamp|window", names(trainDf))
names(trainDf)[1:7]
trainDF <- read.csv("./data/pml-training.csv", na.strings=c("#DIV/0!","NA"))
testDF <- read.csv("./data/pml-testing.csv", na.strings=c("#DIV/0!","NA"))
names(trainDf)[1:7]
grepl("^X|user|timestamp|window", names(trainDF))
trainDF <- trainDF[, !remCol]
testDF <- testDF[, !remCol]
remCol <- grepl("^X|user|timestamp|window", names(trainDF))
trainDF <- trainDF[, !remCol]
testDF <- testDF[, !remCol]
nzv <- nearZeroVar(trainDF, saveMetrics=TRUE)
nzv <- nearZeroVar(trainDF)
trainDF_filtered <- trainDF[, -nzv]
testDF_filtered <- testDF[, -nzv]
str(trainDF_filtered)
knitr::opts_chunk$set(echo = TRUE)
sum(complete.cases(trainDF))
sum(complete.cases(testDF))
#remove missing values
#data.testing <- data.testing[, colSums(is.na(data.testing)) == 0]
#data.training <- data.training[, colSums(is.na(data.training)) == 0]
# We will remove columns 1 to 7:
names(trainDf)[1:7]
sum(complete.cases(trainDF))
sum(complete.cases(testDF))
#remove missing values
#data.testing <- data.testing[, colSums(is.na(data.testing)) == 0]
#data.training <- data.training[, colSums(is.na(data.training)) == 0]
# We will remove columns 1 to 7:
names(trainDF)[1:7]
# Remove:
remCol <- grepl("^X|user|timestamp|window", names(trainDF))
trainDF <- trainDF[, !remCol]
testDF <- testDF[, !remCol]
# Removing zero covariates
#suppressPackageStartupMessages(require(caret))
#nzv <- nearZeroVar(trainDF, saveMetrics=TRUE)
nzv <- nearZeroVar(trainDF)
trainDF_filtered <- trainDF[, -nzv]
testDF_filtered <- testDF[, -nzv]
# Remove predictors with 80% or more missing values
#Train <- trainDF_filtered[, colSums(is.na(trainDF_filtered)) <= 0.8*nrow(trainDF_filtered)]
#Test <- testDF_filtered[, colSums(is.na(testDF_filtered)) <= 0.8*nrow(testDF_filtered)]
nrow(trainDF_filtered)
nrow(trainDF_filtered)]*0.8
nrow(trainDF_filtered)*0.8
colSums(is.na(trainDF_filtered)
)
trainDF_filtered[, colSums(is.na(trainDF_filtered))
)
trainDF_filtered[, colSums(is.na(trainDF_filtered))
]
trainDF_filtered[, colSums(is.na(trainDF_filtered)) <= 0.8*nrow(trainDF_filtered)]
Train <- trainDF_filtered[, colSums(is.na(trainDF_filtered)) <= 0.8*nrow(trainDF_filtered)]
Test <- testDF_filtered[, colSums(is.na(testDF_filtered)) <= 0.8*nrow(testDF_filtered)]
sum(Train$roll_belt)
sum(trainDF_filtered$roll_belt)
set.seed(22561)
inTrain <- createDataPartition(trainDF_filtered$classe, p=0.70, list=F)
training <- trainDF_filtered[inTrain, ]
testing <- trainDF_filtered[-inTrain, ]
dim(training)
dim(testing)
rf_model <- train(classe~., data = training, method = "rf", trControl=trainControl(method="cv",number=5))
modelFit <- train(classe ~., data=training, method="rf")
modelFit
print(modelFit)
training
training$classe
modelFit <- train(classe ~., data=training, method="rf")
table(training$classe)
library(randomForest)
class(traingin)
class(trainging)
class(training)
modelFit <- train(classe ~., data=training, method="rf")
modelFit <- train(classe ~., data=training, method="rf", trControl=controlCV))
modelFit <- train(classe ~., data=training, method="rf", trControl=controlCV)
training <- training[, colSums(is.na(training)) == 0]
modelFit <- train(classe ~., data=training, method="rf")
modelFit <- train(classe ~., data=training, method="rf")
install.packages("doMC")
modelFit <- train(classe ~., data=training, method="rf")
modFitA1 <- rpart(classe ~ ., data=training, method="class")
fancyRpartPlot(modFitA1)
RpartPlot(modFitA1)
plot(modFitA1)
predictionsA1 <- predict(modFitA1, testing, type = "class")
confusionMatrix(predictionsA1, testing$classe)
modFitB1 <- randomForest(classe ~. , data=myTraining)
modFitB1 <- randomForest(classe ~. , data=training)
predictionsB1 <- predict(modFitB1, testing, type = "class")
predictionsB1
confusionMatrix(predictionsB1, testing$classe)
